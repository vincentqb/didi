{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of the data from the [Di-Tech Challenge](http://research.xiaojukeji.com/competition), organized by Didi Chuxing, a ride-hailing company in China. The data is described [here](http://research.xiaojukeji.com/competition/detail.action?competitionId=DiTech2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Info Table\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Field</th>\n",
    "            <th>Type</th>\n",
    "            <th>Meaning</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>order_id</td>\n",
    "            <td>string</td>\n",
    "            <td>order ID</td>\n",
    "            <td>70fc7c2bd2caf386bb50f8fd5dfef0cf</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>driver_id</td>\n",
    "            <td>string</td>\n",
    "            <td>driver ID</td>\n",
    "            <td>56018323b921dd2c5444f98fb45509de</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>passenger_id</td>\n",
    "            <td>string</td>\n",
    "            <td>user ID</td>\n",
    "            <td>238de35f44bbe8a67bdea86a5b0f4719</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>start_district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>departure</td>\n",
    "            <td>d4ec2125aff74eded207d2d915ef682f</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dest_district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>destination</td>\n",
    "            <td>929ec6c160e6f52c20a4217c7978f681</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Price</td>\n",
    "            <td>double</td>\n",
    "            <td>Price</td>\n",
    "            <td>37.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Time</td>\n",
    "            <td>string</td>\n",
    "            <td>Timestamp of the order</td>\n",
    "            <td>2016-01-15 00:35:11</td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "The Order Info Table shows the basic information of an order, including the passenger and the driver (if driver_id =NULL, it means the order was not answered by any driver), place of origin, destination, price and time. The fields order_id, driver_id, passenger_id, start_hash, and dest_hash are made not sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns in order files\n",
    "columns = ['order_id', 'driver_id', 'passenger_id', 'start_district_hash', 'dest_district_hash', 'price', 'time']\n",
    "\n",
    "# Open only one file\n",
    "# order_file_1 = \"data/season_1/training_data/order_data/order_data_2016-01-01\"\n",
    "# df = df_1 = pd.read_csv(order_file_1, sep = \"\\t\", names = columns, parse_dates = 'time')\n",
    "\n",
    "# print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Files are organized by dates\n",
    "# order_files = [\"data/season_1/training_data/order_data/order_data_2016-01-{:02d}\".format(i) for i in range(1, 22)]\n",
    "order_files = [\"data/season_1/training_data/order_data/order_data_2016-01-{:02d}\".format(i) for i in range(1, 3)]\n",
    "\n",
    "# Open all of them\n",
    "order_dfs = []\n",
    "for order_file in order_files:\n",
    "    order_dfs.append(pd.read_csv(order_file, sep = \"\\t\", names = columns, parse_dates = 'time'))\n",
    "df = pd.concat(order_dfs)\n",
    "\n",
    "# Recognize time column as time\n",
    "df.loc[:,'time'] = pd.to_datetime(df.time)\n",
    "\n",
    "# Keep a random number of the rows\n",
    "df_train = df.sample(frac = 0.70, random_state = 111)\n",
    "df_valid = df.loc[~df.index.isin(df_train.index)]\n",
    "df = df_train # avoid looking at validation set during the exploration\n",
    "\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quick look at the data frame\n",
    "print(df.describe())\n",
    "\n",
    "# Find the range of dates\n",
    "print(\"Dates from {} to {}.\".format(df['time'].min(), df['time'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count how many rows per order_id and driver_id\n",
    "count = df[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "count = count['driver_id']\n",
    "\n",
    "# Orders picked up by more than one driver?\n",
    "print(sum(count > 1))\n",
    "# Yes..? Surprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turns out there are duplicate and almost-duplicate entries. \n",
    "# For now, let's keep the last ones.\n",
    "dup = df.duplicated(['order_id', 'driver_id', 'passenger_id', 'time'], keep = 'last')\n",
    "df = df[~dup]\n",
    "# Depending on the test data, it might be a better idea to leave them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count how many rows per order_id and driver_id\n",
    "count = df[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "count = count['driver_id']\n",
    "\n",
    "# Orders picked up by more than one driver?\n",
    "print(sum(count > 1))\n",
    "# No more.\n",
    "\n",
    "# Create gap column\n",
    "gap = (count == 0).astype('int').tolist()\n",
    "df.loc[:,'gap'] = gap\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proportion of orders not picked up by a driver\n",
    "s = sum(count == 0)\n",
    "l = len(count)\n",
    "\n",
    "print(\"There are {} orders-without-drivers out of {} orders: {:.1%}.\".format(s, l, s/l))\n",
    "# It appears the gap is simply the number of orders not picked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute time slot\n",
    "\n",
    "# Extract the date, and implicitly make the time midnight.\n",
    "df.loc[:,'date'] = pd.to_datetime(df.time.dt.date)\n",
    "# df.loc[:,'timeonly'] = df.datetime.dt.time\n",
    "\n",
    "# One day is uniformly divided into 144 ten minute time slots.\n",
    "df.loc[:,'timeslot'] = (df['time'] - df['date']).astype('timedelta64[m]')//10\n",
    "\n",
    "# Drop the time column\n",
    "# df = df.drop('time', axis = 1)\n",
    "\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute gap per time slot per district\n",
    "df_select = df[['start_district_hash', 'date', 'timeslot', 'gap']]\n",
    "df_gap = df_select.groupby(['start_district_hash', 'date', 'timeslot']).sum()\n",
    "\n",
    "# Flatten data frame after the group by\n",
    "df_gap = df_gap.reset_index()\n",
    "print(df_gap.head(2))\n",
    "\n",
    "# Sanity check: do the numbers add up?\n",
    "print(sum(df_gap.gap))\n",
    "# Yup.\n",
    "\n",
    "df = df_gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# District Info Table\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Field</th>\n",
    "            <th>Type</th>\n",
    "            <th>Meaning</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>District hash</td>\n",
    "            <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>district_id</td>\n",
    "            <td>string</td>\n",
    "            <td>District ID</td>\n",
    "            <td>1</td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "The District Info Table shows the information about the districts to be evaluated in the contest. You need to do the prediction given the districts from the District Definition Table. In the submission of the results, you need to map the district hash value to district mapped ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "district_file = 'data/season_1/training_data/cluster_map/cluster_map'\n",
    "district = pd.read_csv(district_file, sep = '\\t', names = ['district_hash', 'district_id'])\n",
    "district_renamed = district.rename(columns = {'district_hash': 'start_district_hash'})\n",
    "\n",
    "# Attach district_id to data frame\n",
    "df = df.merge(district_renamed, on = 'start_district_hash', how = 'left')\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Data name</th>\n",
    "            <th>Data type</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>District ID</td>\n",
    "            <td>string</td>\n",
    "            <td>1,2,3,4 (the same as district mapping ID)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Time slot</td>\n",
    "            <td>string</td>\n",
    "            <td>2016-01-23-1 (The first time slot on Jan. 23rd, 2016; one day is uniformly divided into 144 ten minute time slots)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Prediction value</td>\n",
    "            <td>double</td>\n",
    "            <td>6.0</td>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = df[['district_id', 'date', 'timeslot']]\n",
    "train_label = df['gap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the date - timeslot column for predictions\n",
    "df.loc[:,'datetimeslot'] = df.date.dt.date.map(str) + '-' + df.timeslot.astype(int).map(str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
