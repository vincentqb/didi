{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of the data from the [Di-Tech Challenge](http://research.xiaojukeji.com/competition), organized by Didi Chuxing, a ride-hailing company in China. The data is described [here](http://research.xiaojukeji.com/competition/detail.action?competitionId=DiTech2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Warn about chained assignment?\n",
    "# pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Info Table\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Field</th>\n",
    "            <th>Type</th>\n",
    "            <th>Meaning</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>order_id</td>\n",
    "            <td>string</td>\n",
    "            <td>order ID</td>\n",
    "            <td>70fc7c2bd2caf386bb50f8fd5dfef0cf</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>driver_id</td>\n",
    "            <td>string</td>\n",
    "            <td>driver ID</td>\n",
    "            <td>56018323b921dd2c5444f98fb45509de</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>passenger_id</td>\n",
    "            <td>string</td>\n",
    "            <td>user ID</td>\n",
    "            <td>238de35f44bbe8a67bdea86a5b0f4719</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>start_district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>departure</td>\n",
    "            <td>d4ec2125aff74eded207d2d915ef682f</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dest_district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>destination</td>\n",
    "            <td>929ec6c160e6f52c20a4217c7978f681</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Price</td>\n",
    "            <td>double</td>\n",
    "            <td>Price</td>\n",
    "            <td>37.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Time</td>\n",
    "            <td>string</td>\n",
    "            <td>Timestamp of the order</td>\n",
    "            <td>2016-01-15 00:35:11</td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "The Order Info Table shows the basic information of an order, including the passenger and the driver (if driver_id =NULL, it means the order was not answered by any driver), place of origin, destination, price and time. The fields order_id, driver_id, passenger_id, start_hash, and dest_hash are made not sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns in order files\n",
    "columns = ['order_id', 'driver_id', 'passenger_id', 'start_district_hash', 'dest_district_hash', 'price', 'time']\n",
    "\n",
    "# pd.read_csv?\n",
    "\n",
    "# Open only one file\n",
    "# order_file_1 = \"data/season_1/training_data/order_data/order_data_2016-01-01\"\n",
    "# df = df_1 = pd.read_csv(order_file_1, sep = \"\\t\", names = columns, parse_dates = 'time')\n",
    "\n",
    "# print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Files are organized by dates\n",
    "# order_files = [\"data/season_1/training_data/order_data/order_data_2016-01-{:02d}\".format(i) for i in range(1, 22)]\n",
    "order_files = [\"data/season_1/training_data/order_data/order_data_2016-01-{:02d}\".format(i) for i in range(1, 3)]\n",
    "\n",
    "# Open all of them\n",
    "order_dfs = []\n",
    "for order_file in order_files:\n",
    "    order_dfs.append(pd.read_csv(order_file, sep = \"\\t\", names = columns))\n",
    "df = pd.concat(order_dfs)\n",
    "\n",
    "# Recognize time column as time\n",
    "df['time'] = pd.to_datetime(df.time)\n",
    "\n",
    "# Keep a random number of the rows\n",
    "df_train = df.sample(frac = 0.70, random_state = 111)\n",
    "df_valid = df.loc[~df.index.isin(df_train.index)]\n",
    "df = df_train # avoid looking at validation set during the exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quick look at the data frame\n",
    "\n",
    "print(df.head(2))\n",
    "print(df.describe())\n",
    "print(\"\\nDates from {} to {}.\".format(df['time'].min(), df['time'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count how many rows per order_id and driver_id\n",
    "count = df[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "count = count['driver_id']\n",
    "\n",
    "# Orders picked up by more than one driver?\n",
    "print(sum(count > 1))\n",
    "# Yes..? Surprising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turns out there are duplicate and almost-duplicate entries. \n",
    "# For now, let's keep the last ones.\n",
    "dup = df.duplicated(['order_id', 'driver_id', 'passenger_id', 'time'], keep = 'last')\n",
    "df = df[~dup]\n",
    "# Depending on the test data, it might be a better idea to leave them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count how many rows per order_id and driver_id\n",
    "count = df[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "count = count['driver_id']\n",
    "\n",
    "# Orders picked up by more than one driver?\n",
    "print(sum(count > 1))\n",
    "# No more.\n",
    "\n",
    "# Create gap column\n",
    "gap = (count == 0).astype('int').tolist()\n",
    "df['gap'] = gap\n",
    "\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Proportion of orders not picked up by a driver\n",
    "s = sum(count == 0)\n",
    "l = len(count)\n",
    "\n",
    "print(\"There are {} orders-without-drivers out of {} orders: {:.1%}.\".format(s, l, s/l))\n",
    "# It appears the gap is simply the number of orders not picked up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute time slot\n",
    "\n",
    "# Extract the date, and implicitly make the time midnight.\n",
    "df['date'] = pd.to_datetime(df.time.dt.date)\n",
    "# df['timeonly'] = df.datetime.dt.time\n",
    "\n",
    "# Is it a weekend or weekday?\n",
    "df['weekend'] = df.time.dt.dayofweek\n",
    "df['weekend'] = df.weekend >= 5\n",
    "\n",
    "# One day is uniformly divided into 144 ten minute time slots.\n",
    "df['timeslot'] = (df['time'] - df['date']).astype('timedelta64[m]')//10\n",
    "\n",
    "# Drop the time column\n",
    "# df = df.drop('time', axis = 1)\n",
    "\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute gap per time slot per district\n",
    "cols = ['start_district_hash', 'date', 'timeslot']\n",
    "df_select = df[cols + ['gap']]\n",
    "df_gap = df_select.groupby(cols).sum()\n",
    "\n",
    "# Flatten data frame after the group by\n",
    "df_gap = df_gap.reset_index()\n",
    "print(df_gap.head(2))\n",
    "\n",
    "# Sanity check: do the numbers add up?\n",
    "print(sum(df_gap.gap))\n",
    "# Yup.\n",
    "\n",
    "# Merge back into main data frame\n",
    "df = df.merge(df_gap, on = cols + ['gap'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# District Info Table\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Field</th>\n",
    "            <th>Type</th>\n",
    "            <th>Meaning</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>District hash</td>\n",
    "            <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>district_id</td>\n",
    "            <td>string</td>\n",
    "            <td>District ID</td>\n",
    "            <td>1</td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "The District Info Table shows the information about the districts to be evaluated in the contest. You need to do the prediction given the districts from the District Definition Table. In the submission of the results, you need to map the district hash value to district mapped ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use the starting district_hash as the associated disctrict\n",
    "df = df.rename(columns = {'start_district_hash': 'district_hash'})\n",
    "\n",
    "# Load district conversion table\n",
    "district_file = 'data/season_1/training_data/cluster_map/cluster_map'\n",
    "district = pd.read_csv(district_file, sep = '\\t', names = ['district_hash', 'district_id'])\n",
    "\n",
    "# Replace district_hash by district_id in data frame\n",
    "df = df.merge(district, on = 'district_hash', how = 'left')\n",
    "df = df.drop('district_hash', axis = 1)\n",
    "\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Data name</th>\n",
    "            <th>Data type</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>District ID</td>\n",
    "            <td>string</td>\n",
    "            <td>1,2,3,4 (the same as district mapping ID)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Time slot</td>\n",
    "            <td>string</td>\n",
    "            <td>2016-01-23-1 (The first time slot on Jan. 23rd, 2016; one day is uniformly divided into 144 ten minute time slots)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Prediction value</td>\n",
    "            <td>double</td>\n",
    "            <td>6.0</td>\n",
    "        </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make first prediction by simply taking the mean per district_id per timeslot per weekend\n",
    "cols = ['district_id', 'weekend', 'timeslot']\n",
    "\n",
    "df_select = df[cols + ['gap']]\n",
    "gap_mean = df_select.groupby(cols).mean().reset_index()\n",
    "gap_mean = gap_mean.rename(columns = {'gap': 'gap_mean'})\n",
    "\n",
    "df = df.merge(gap_mean, on = cols, how = 'left')\n",
    "\n",
    "print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup training set, labels, and predictions.\n",
    "train_data = df[['district_id', 'date', 'timeslot']]\n",
    "train_outcome = df['gap']\n",
    "train_predict = df['gap_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the date - timeslot column for predictions\n",
    "train_data['datetimeslot'] = df.date.dt.date.map(str) + '-' + df.timeslot.astype(int).map(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider di districts and tj time slots, and the supply-demand gap gapij , and your prediction is sij, we use as the evaluation metrics: \n",
    "![MAPE](figures/mape.jpg)\n",
    "The lowest MAPE will be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MAPE(outcome, predict):\n",
    "    # Compute MAPE score. Lower is better.\n",
    "    import numpy as np\n",
    "    diff = (outcome - predict) / outcome.replace({0: np.nan})\n",
    "    diff = diff.replace({np.nan: 0})\n",
    "    return diff.mean() # Compute the average over all district and timeslots\n",
    "\n",
    "mape = MAPE(train_outcome, train_predict)\n",
    "print(mape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
