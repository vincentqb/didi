{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploration of the data from the [Di-Tech Challenge](http://research.xiaojukeji.com/competition), organized by Didi Chuxing, a ride-hailing company in China. The data is described [here](http://research.xiaojukeji.com/competition/detail.action?competitionId=DiTech2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Are you running for the final submission?\n",
    "final_submission = False\n",
    "# final_submission = True\n",
    "\n",
    "# Paths\n",
    "path_to_data = 'data/season_1/'\n",
    "# test_set_number = '1'\n",
    "test_set_number = '2'\n",
    "path_to_test = path_to_data + 'test_set_' + test_set_number + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vincent/.local/lib/python3.6/site-packages/ggplot/utils.py:81: FutureWarning: pandas.tslib is deprecated and will be removed in a future version.\n",
      "You can access Timestamp as pandas.Timestamp\n",
      "  pd.tslib.Timestamp,\n",
      "/home/vincent/.local/lib/python3.6/site-packages/ggplot/stats/smoothers.py:4: FutureWarning: The pandas.lib module is deprecated and will be removed in a future version. These are private functions and can be accessed from pandas._libs.lib instead\n",
      "  from pandas.lib import Timestamp\n",
      "/home/vincent/.local/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from time import clock\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Warn about chained assignment in pandas?\n",
    "# pd.options.mode.chained_assignment = None\n",
    "\n",
    "if not final_submission:\n",
    "    \n",
    "    # import matplotlib\n",
    "    # matplotlib.use('Agg')\n",
    "\n",
    "    from ggplot import *\n",
    "    %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Info Table\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Field</th>\n",
    "            <th>Type</th>\n",
    "            <th>Meaning</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>order_id</td>\n",
    "            <td>string</td>\n",
    "            <td>order ID</td>\n",
    "            <td>70fc7c2bd2caf386bb50f8fd5dfef0cf</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>driver_id</td>\n",
    "            <td>string</td>\n",
    "            <td>driver ID</td>\n",
    "            <td>56018323b921dd2c5444f98fb45509de</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>passenger_id</td>\n",
    "            <td>string</td>\n",
    "            <td>user ID</td>\n",
    "            <td>238de35f44bbe8a67bdea86a5b0f4719</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>start_district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>departure</td>\n",
    "            <td>d4ec2125aff74eded207d2d915ef682f</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>dest_district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>destination</td>\n",
    "            <td>929ec6c160e6f52c20a4217c7978f681</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Price</td>\n",
    "            <td>double</td>\n",
    "            <td>Price</td>\n",
    "            <td>37.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Time</td>\n",
    "            <td>string</td>\n",
    "            <td>Timestamp of the order</td>\n",
    "            <td>2016-01-15 00:35:11</td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "The Order Info Table shows the basic information of an order, including the passenger and the driver (if driver_id =NULL, it means the order was not answered by any driver), place of origin, destination, price and time. The fields order_id, driver_id, passenger_id, start_hash, and dest_hash are made not sensitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>start_district_hash</th>\n",
       "      <th>dest_district_hash</th>\n",
       "      <th>price</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8eb94f6832600ee0d342d8a931f64df7</td>\n",
       "      <td>a51979c9a0b257fa81cc401ac8addc97</td>\n",
       "      <td>114cfc989cea164e63d3405fe3055d09</td>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-01-10 19:42:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>982ca599b83542f32a62fa63fdc25681</td>\n",
       "      <td>9f5decbb0180ab1979ff293bec7d1f93</td>\n",
       "      <td>d52994586c13b6066fd031ba7f684e24</td>\n",
       "      <td>62afaf3288e236b389af9cfdc5206415</td>\n",
       "      <td>62afaf3288e236b389af9cfdc5206415</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016-01-10 14:24:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                         driver_id  \\\n",
       "0  8eb94f6832600ee0d342d8a931f64df7  a51979c9a0b257fa81cc401ac8addc97   \n",
       "1  982ca599b83542f32a62fa63fdc25681  9f5decbb0180ab1979ff293bec7d1f93   \n",
       "\n",
       "                       passenger_id               start_district_hash  \\\n",
       "0  114cfc989cea164e63d3405fe3055d09  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
       "1  d52994586c13b6066fd031ba7f684e24  62afaf3288e236b389af9cfdc5206415   \n",
       "\n",
       "                 dest_district_hash  price                time  \n",
       "0  90c5a34f06ac86aee0fd70e2adce7d8a    7.0 2016-01-10 19:42:02  \n",
       "1  62afaf3288e236b389af9cfdc5206415    8.0 2016-01-10 14:24:23  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_orders(order_files):\n",
    "    \"\"\"\n",
    "    Create data frames for order data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Columns in order files\n",
    "    columns = ['order_id', 'driver_id', 'passenger_id', \n",
    "               'start_district_hash', 'dest_district_hash', 'price', 'time']\n",
    "\n",
    "    # Open all of them\n",
    "    order_dfs = []\n",
    "    for order_file in order_files:\n",
    "        order_dfs.append(pd.read_csv(order_file, sep = \"\\t\", names = columns))\n",
    "    df = pd.concat(order_dfs)\n",
    "\n",
    "    # Recognize time column as time\n",
    "    df['time'] = pd.to_datetime(df.time)\n",
    "    # Set the row labels to the time stamp\n",
    "    # df = df.set_index('time')\n",
    "\n",
    "    return df\n",
    "\n",
    "# Files are organized by dates\n",
    "if final_submission:\n",
    "    order_files = glob.glob(path_to_data + 'training_data/order_data/*')\n",
    "else:\n",
    "    order_files = [path_to_data + \"training_data/order_data/order_data_2016-01-{:02d}\".format(i) \n",
    "                   for i in range(10, 16)]\n",
    "\n",
    "df = load_orders(order_files)\n",
    "\n",
    "# Keep first two weeks for training, next one week for validation.\n",
    "ind = df['time'] < pd.to_datetime('2016-01-15')\n",
    "df_train = df[ind]\n",
    "df_valid = df[~ind]\n",
    "\n",
    "# Keep a random number of the rows\n",
    "# df_train = df.sample(frac = 0.70, random_state = 111)\n",
    "# df_valid = df[~df.index.isin(df_train.index)]\n",
    "\n",
    "# Avoid looking at validation set during the exploration\n",
    "df = df_train\n",
    "\n",
    "# Quick look at the data frame\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime64[ns]    1\n",
       "float64           1\n",
       "object            5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.get_dtype_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates from 2016-01-10 00:00:03 to 2016-01-14 23:59:57.\n",
      "1979690 entries\n",
      "1975907 unique orders (99.8%)\n",
      "654563 unique passengers (33.1%)\n",
      "66048 unique drivers (3.3%)\n",
      "66 unique starting districts (0.0%)\n",
      "538 unique destination districts (0.0%)\n",
      "\n",
      "\n",
      "count    1.979690e+06\n",
      "mean     1.684720e+01\n",
      "std      1.598257e+01\n",
      "min      0.000000e+00\n",
      "25%      7.900000e+00\n",
      "50%      1.210000e+01\n",
      "75%      2.100000e+01\n",
      "max      5.120000e+02\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Dates?\n",
    "\n",
    "print(\"Dates from {} to {}.\".format(df['time'].min(), df['time'].max()))\n",
    "\n",
    "# How many entries? unique orders/passengers/drivers?\n",
    "\n",
    "num_entries = df.shape[0]\n",
    "print(\"{} entries\".format(num_entries))\n",
    "\n",
    "num_orders = len(df.order_id.unique())\n",
    "print(\"{} unique orders ({:.1%})\".format(num_orders, num_orders/num_entries))\n",
    "\n",
    "num_pass = len(df.passenger_id.unique())\n",
    "print(\"{} unique passengers ({:.1%})\".format(num_pass, num_pass/num_entries))\n",
    "      \n",
    "num_drivers = len(df.driver_id.unique())\n",
    "print(\"{} unique drivers ({:.1%})\".format(num_drivers, num_drivers/num_entries))\n",
    "\n",
    "num_start_district = len(df.start_district_hash.unique())\n",
    "print(\"{} unique starting districts ({:.1%})\".format(num_start_district, num_start_district/num_entries))\n",
    "\n",
    "num_dest_district = len(df.dest_district_hash.unique())\n",
    "print(\"{} unique destination districts ({:.1%})\".format(num_dest_district, num_dest_district/num_entries))\n",
    "\n",
    "# Price distribution\n",
    "\n",
    "print(\"\\n\")\n",
    "print(df.price.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>start_district_hash</th>\n",
       "      <th>dest_district_hash</th>\n",
       "      <th>price</th>\n",
       "      <th>time</th>\n",
       "      <th>date</th>\n",
       "      <th>timeonly</th>\n",
       "      <th>timeslot_absolute</th>\n",
       "      <th>timeslot_day</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>dow</th>\n",
       "      <th>weekend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8eb94f6832600ee0d342d8a931f64df7</td>\n",
       "      <td>a51979c9a0b257fa81cc401ac8addc97</td>\n",
       "      <td>114cfc989cea164e63d3405fe3055d09</td>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2016-01-10 19:42:02</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>19:42:02</td>\n",
       "      <td>1414.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>982ca599b83542f32a62fa63fdc25681</td>\n",
       "      <td>9f5decbb0180ab1979ff293bec7d1f93</td>\n",
       "      <td>d52994586c13b6066fd031ba7f684e24</td>\n",
       "      <td>62afaf3288e236b389af9cfdc5206415</td>\n",
       "      <td>62afaf3288e236b389af9cfdc5206415</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016-01-10 14:24:23</td>\n",
       "      <td>2016-01-10</td>\n",
       "      <td>14:24:23</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           order_id                         driver_id  \\\n",
       "0  8eb94f6832600ee0d342d8a931f64df7  a51979c9a0b257fa81cc401ac8addc97   \n",
       "1  982ca599b83542f32a62fa63fdc25681  9f5decbb0180ab1979ff293bec7d1f93   \n",
       "\n",
       "                       passenger_id               start_district_hash  \\\n",
       "0  114cfc989cea164e63d3405fe3055d09  90c5a34f06ac86aee0fd70e2adce7d8a   \n",
       "1  d52994586c13b6066fd031ba7f684e24  62afaf3288e236b389af9cfdc5206415   \n",
       "\n",
       "                 dest_district_hash  price                time        date  \\\n",
       "0  90c5a34f06ac86aee0fd70e2adce7d8a    7.0 2016-01-10 19:42:02  2016-01-10   \n",
       "1  62afaf3288e236b389af9cfdc5206415    8.0 2016-01-10 14:24:23  2016-01-10   \n",
       "\n",
       "   timeonly  timeslot_absolute  timeslot_day  timeslot  dow  weekend  \n",
       "0  19:42:02             1414.0         118.0     119.0    6     True  \n",
       "1  14:24:23             1382.0          86.0      87.0    6     True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach time-related info \n",
    "\n",
    "def compute_timeinfo(df, dateonly = False):\n",
    "    # Input: data frame with time (or date) column.\n",
    "    \n",
    "    if dateonly:\n",
    "        # Determine day of week, weekend.\n",
    "        df['dow'] = pd.to_datetime(df.date).dt.dayofweek\n",
    "        df['weekend'] = df.dow >= 5\n",
    "    else:\n",
    "        # Extract the date, and implicitly make the time midnight.\n",
    "        df['date'] = df.time.dt.date\n",
    "        df['timeonly'] = df.time.dt.time\n",
    "        \n",
    "        # Compute 10-min timeslots -- absolute and per day.\n",
    "        df['timeslot_absolute'] = (df['time'] - pd.to_datetime('2016-01-01')).astype('timedelta64[m]')//10\n",
    "        df['timeslot_day'] = df['timeslot_absolute'] % (24 * 6)\n",
    "        df['timeslot'] = df['timeslot_day'] % (24*6) + 1\n",
    "    \n",
    "        # Determine day of week, weekend.\n",
    "        df['dow'] = df.time.dt.dayofweek\n",
    "        df['weekend'] = df.dow >= 5\n",
    "    \n",
    "        # Drop the time column?\n",
    "        # df = df.drop('time', axis = 1)\n",
    "    \n",
    "compute_timeinfo(df)\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot of gap vs elapsed time in days group by ten minutes interval\n",
    "\n",
    "# Convert to days\n",
    "df['time_from_begin'] = df['timeslot_absolute']/6/24\n",
    "\n",
    "# Count how many rows per timeslot\n",
    "# count = df[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "count = df.groupby('time_from_begin')['time_from_begin'].count()\n",
    "count = pd.DataFrame(count)\n",
    "count.columns = ['count']\n",
    "count.reset_index(level=0, inplace=True)\n",
    "\n",
    "if not final_submission:\n",
    "    ggplot(aes('time_from_begin', 'count'), data = count) + \\\n",
    "        geom_point(color = 'gray') + \\\n",
    "        geom_line() + \\\n",
    "        xlab('Elapsed time in days') + ylab('Order count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 10 most popular districts account for 1327943 out of 1979690 (67.1%)\n"
     ]
    }
   ],
   "source": [
    "# Ranking districts\n",
    "districts_count = df['start_district_hash'].value_counts(sort = True)\n",
    "\n",
    "# Number of most popular districts to keep\n",
    "k = 10\n",
    "num_entries = df.shape[0]\n",
    "num_top = districts_count[:10].sum()\n",
    "\n",
    "# Look at k top districts\n",
    "print(\"The first {} most popular districts account for {} out of {} ({:.1%})\".format(\n",
    "        k, num_top, num_entries, num_top/num_entries))\n",
    "\n",
    "# Rank districts\n",
    "districts_rank = districts_count.rank(ascending = False, method = 'dense')\n",
    "districts_top = districts_rank[districts_rank <= k].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 317114 orders-without-drivers out of 1979690 orders: 16.0%.\n"
     ]
    }
   ],
   "source": [
    "# Count how many rows per order_id and driver_id\n",
    "# count = df[['order_id', 'driver_id']].groupby('order_id').count()\n",
    "# count = count.reset_index()\n",
    "# count = count['driver_id']\n",
    "\n",
    "# Orders picked up by more than one driver?\n",
    "# print(\"Number of orders taken by more than one driver: {}\".format(sum(count > 1)))\n",
    "# Yes..? Surprising.\n",
    "\n",
    "# Turns out there are duplicate and almost-duplicate entries. \n",
    "# The FAQ recommends just leaving them in.\n",
    "\n",
    "# Remove the duplicates\n",
    "# dup = df.duplicated(['order_id', 'driver_id', 'passenger_id', 'time'], keep = 'last')\n",
    "# df = df[~dup]\n",
    "\n",
    "# Was order answered?\n",
    "df['is_gap'] = df['driver_id'].isnull()\n",
    "\n",
    "# Proportion of orders not picked up by a driver\n",
    "s = sum(df['is_gap'])\n",
    "l = len(df['is_gap'])\n",
    "print(\"There are {} orders-without-drivers out of {} orders: {:.1%}.\".format(s, l, s/l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot of gap vs elapsed time in days group by ten minutes interval\n",
    "\n",
    "cols = ['time_from_begin']\n",
    "df_select = df[cols + ['is_gap']]\n",
    "df_gap = df_select.groupby(cols).sum()\n",
    "df_gap = df_gap.reset_index()\n",
    "\n",
    "if not final_submission:\n",
    "    ggplot(aes('time_from_begin', 'is_gap'), data = df_gap) + \\\n",
    "        geom_point(color = 'gray') + \\\n",
    "        geom_line() + \\\n",
    "        xlab('Elapsed time in days') + ylab('Gap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_prior_gap(df):\n",
    "    \"\"\"\n",
    "    Find the gap for the three prior time slots. \n",
    "    Using shift is fast, but might not lead to the timeslots corresponding to the last 30 min.\n",
    "    \"\"\"\n",
    "    \n",
    "    # df.sort_values(by = 'timeslot_absolute', inplace = True)\n",
    "    df.sort_values(by = ['date', 'timeslot'], inplace = True)\n",
    "    df_grouped = df.groupby(['start_district_hash'])\n",
    "    \n",
    "    df['gap_before_1'] = df_grouped.shift(1).gap.fillna(method = 'bfill')\n",
    "    df['gap_before_2'] = df_grouped.shift(2).gap.fillna(method = 'bfill')\n",
    "    df['gap_before_3'] = df_grouped.shift(3).gap.fillna(method = 'bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317114.0\n"
     ]
    }
   ],
   "source": [
    "# Make new data frame with gap per timeslot per district\n",
    "\n",
    "def compute_gap(df):\n",
    "    \n",
    "    # Compute gap column\n",
    "    # df['gap'] = df.groupby(cols).driver_id.isnull().transform('sum')\n",
    "    \n",
    "    # Gap is when no driver\n",
    "    df['is_gap'] = df['driver_id'].isnull()\n",
    "    \n",
    "    # Aggregate\n",
    "    cols = ['start_district_hash', 'date', 'timeslot']\n",
    "    df_select = df[cols + ['is_gap']]\n",
    "    df_gap = df_select.groupby(cols).sum()\n",
    "    \n",
    "    # Flatten data frame\n",
    "    df_gap = df_gap.reset_index()\n",
    "    df_gap = df_gap.rename(columns = {'is_gap': 'gap'})\n",
    "    \n",
    "    # Add prior gap columns\n",
    "    find_prior_gap(df_gap)\n",
    "    \n",
    "    return df_gap\n",
    "\n",
    "# Compute gap. Only care about new data frame now.\n",
    "df = compute_gap(df)\n",
    "\n",
    "# Sanity check: do the number add up?\n",
    "print(sum(df.gap))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Field</th>\n",
    "            <th>Type</th>\n",
    "            <th>Meaning</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Time</td>\n",
    "            <td>string</td>\n",
    "            <td>Timestamp</td>\n",
    "            <td>2016-01-15 00:35:11</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Weather</td>\n",
    "            <td>int</td>\n",
    "            <td>Weather</td>\n",
    "            <td>7</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>temperature</td>\n",
    "            <td>double</td>\n",
    "            <td>Temperature</td>\n",
    "            <td>-9</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>PM2.5</td>\n",
    "            <td>double</td>\n",
    "            <td>pm25</td>\n",
    "            <td>66</td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "The Weather Info Table shows the weather info every 10 minutes each city. The weather field gives the weather conditions such as sunny, rainy, and snowy etc; all sensitive information has been removed. The unit of temperature is Celsius degree, and PM2.5 is the level of air pollutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_weather(weather_files):\n",
    "\n",
    "    # Open all of them\n",
    "    columns = ['time', 'weather', 'temperature', 'pm25']\n",
    "    weather_dfs = []\n",
    "    for f in weather_files:\n",
    "        weather_dfs.append(pd.read_csv(f, sep = \"\\t\", names = columns))\n",
    "    dfw = pd.concat(weather_dfs)\n",
    "\n",
    "    # Extract date and time slot\n",
    "    dfw['time'] = pd.to_datetime(dfw.time)\n",
    "    dfw['date'] = dfw.time.dt.date\n",
    "    dfw['timeslot'] = (dfw['time'] - pd.to_datetime(dfw['date'])).astype('timedelta64[m]')//10 + 1\n",
    "    dfw = dfw.drop('time', axis = 1)\n",
    "\n",
    "    return dfw\n",
    "\n",
    "# Files are organized by dates\n",
    "weather_files = glob.glob(path_to_data + 'training_data/weather_data/*')\n",
    "dfw = load_weather(weather_files)\n",
    "# dfw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_weather(df, dfw):\n",
    "    # Merge into main data frame, and fill missing values\n",
    "    # http://pandas.pydata.org/pandas-docs/stable/missing_data.html\n",
    "    \n",
    "    df = df.merge(dfw, on = ['date', 'timeslot'], how = 'left')\n",
    "    \n",
    "    # Fill missing values with forward/backward fills\n",
    "    df.sort_values(by = ['date', 'timeslot'], inplace = True)\n",
    "    df.temperature = df.temperature.fillna(method = 'ffill')\n",
    "    df.temperature = df.temperature.fillna(method = 'bfill')\n",
    "    \n",
    "    # ... or interpolation\n",
    "    # df.temperature = df.temperature.interpolate(method = 'time')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = merge_weather(df, dfw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create conversion table\n",
    "districts_convert = pd.DataFrame(data = districts_rank)\n",
    "districts_convert.reset_index(level = 0, inplace = True)\n",
    "districts_convert.columns = ['start_district_hash', 'start_district_rank']\n",
    "# districts_convert.head(2)\n",
    "\n",
    "# Replace hash by rank\n",
    "df = df.merge(districts_convert, on = 'start_district_hash', how = 'left')\n",
    "# df = df.drop('start_district_hash', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(df):\n",
    "    \"\"\"\n",
    "    One-hot encode categorical column for most-popular district hash.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Look only at most popular districts\n",
    "    df['district'] = np.nan\n",
    "    df.loc[df.start_district_hash.isin(districts_top), 'district'] = \\\n",
    "        df.loc[df.start_district_hash.isin(districts_top), 'start_district_hash']\n",
    "    \n",
    "    # One-hot encoding\n",
    "    dummies = pd.get_dummies(df['district'], dummy_na = False)\n",
    "    df = pd.concat((df.drop('district', axis = 1), dummies.astype(int)), axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# df = one_hot_encode(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# District Info Table\n",
    "\n",
    "<table>\n",
    "        <tr>\n",
    "            <th>Field</th>\n",
    "            <th>Type</th>\n",
    "            <th>Meaning</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>district_hash</td>\n",
    "            <td>string</td>\n",
    "            <td>District hash</td>\n",
    "            <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>district_id</td>\n",
    "            <td>string</td>\n",
    "            <td>District ID</td>\n",
    "            <td>1</td>\n",
    "        </tr>\n",
    "</table>\n",
    "\n",
    "The District Info Table shows the information about the districts to be evaluated in the contest. You need to do the prediction given the districts from the District Definition Table. In the submission of the results, you need to map the district hash value to district mapped ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 66 districts in the district file.\n"
     ]
    }
   ],
   "source": [
    "# Use the starting district_hash as the associated disctrict\n",
    "col = 'start_district_hash'\n",
    "\n",
    "# Load district conversion table\n",
    "district_file = path_to_data + 'training_data/cluster_map/cluster_map'\n",
    "district = pd.read_csv(district_file, sep = '\\t', names = [col, 'district_id'])\n",
    "\n",
    "# How many districts?\n",
    "print(\"There are {} districts in the district file.\".format(district.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Columns in order files\n",
    "columns = ['datetimeslot']\n",
    "\n",
    "# Open list of slots\n",
    "order_file = path_to_test + 'read_me_' + test_set_number + '.txt'\n",
    "df_test_slots = pd.read_csv(order_file, sep = \"\\t\", names = columns, skiprows = 1)\n",
    "\n",
    "# Extract date and timeslot [0,143]\n",
    "df_test_slots['date'] = pd.to_datetime(df_test_slots.datetimeslot.str[:10])\n",
    "df_test_slots['timeslot'] = df_test_slots.datetimeslot.str[11:]\n",
    "df_test_slots['timeslot'] = df_test_slots.timeslot.astype(int)\n",
    "compute_timeinfo(df_test_slots, dateonly = True)\n",
    "\n",
    "# Create all combination of districts and time slots\n",
    "df_test_slots['to_predict'] = True\n",
    "district['to_predict'] = True\n",
    "df_test_slots = df_test_slots.merge(district, on = 'to_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load test order files\n",
    "order_files = glob.glob(path_to_test + 'order_data/*')\n",
    "df_test = load_orders(order_files)\n",
    "\n",
    "# Attach time info\n",
    "compute_timeinfo(df_test)\n",
    "\n",
    "# Compute gap per time slot per district\n",
    "df_test = compute_gap(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge with slots to predict in test set\n",
    "df_test['to_predict'] = False\n",
    "df_test_full = pd.concat([df_test, df_test_slots])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load weather data\n",
    "order_files = glob.glob(path_to_test + 'weather_data/*')\n",
    "dfw_test = load_weather(weather_files)\n",
    "\n",
    "# Get all the weather data\n",
    "dfw_all = pd.concat([dfw, dfw_test])\n",
    "\n",
    "# Merge weather data\n",
    "df_test_full = merge_weather(df_test_full, dfw_all)\n",
    "\n",
    "# Replace district by popularity\n",
    "df_test_full = df_test_full.merge(districts_convert, on = 'start_district_hash', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>datetimeslot</th>\n",
       "      <th>district_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>gap</th>\n",
       "      <th>gap_before_1</th>\n",
       "      <th>gap_before_2</th>\n",
       "      <th>gap_before_3</th>\n",
       "      <th>start_district_hash</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>to_predict</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pm25</th>\n",
       "      <th>start_district_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1afd7afbc81ecc1b13886a569d869e8a</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1c60154546102e6525f68cb4f31e0657</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1cbfbdd079ef93e74405c53fcfff8567</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1ecbb52d73c522f184a6fc53128b1ea1</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2301bc920194c95cf0c7486e5675243c</td>\n",
       "      <td>43.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date datetimeslot  district_id  dow   gap  gap_before_1  \\\n",
       "0  2016-01-23          NaN          NaN  NaN  37.0          37.0   \n",
       "1  2016-01-23          NaN          NaN  NaN   2.0          37.0   \n",
       "2  2016-01-23          NaN          NaN  NaN   5.0          37.0   \n",
       "3  2016-01-23          NaN          NaN  NaN   0.0          37.0   \n",
       "4  2016-01-23          NaN          NaN  NaN   3.0          37.0   \n",
       "\n",
       "   gap_before_2  gap_before_3               start_district_hash  timeslot  \\\n",
       "0          37.0          37.0  1afd7afbc81ecc1b13886a569d869e8a      43.0   \n",
       "1          37.0          37.0  1c60154546102e6525f68cb4f31e0657      43.0   \n",
       "2          37.0          37.0  1cbfbdd079ef93e74405c53fcfff8567      43.0   \n",
       "3          37.0          37.0  1ecbb52d73c522f184a6fc53128b1ea1      43.0   \n",
       "4          37.0          37.0  2301bc920194c95cf0c7486e5675243c      43.0   \n",
       "\n",
       "   to_predict weekend  weather  temperature  pm25  start_district_rank  \n",
       "0       False     NaN      NaN          NaN   NaN                  9.0  \n",
       "1       False     NaN      NaN          NaN   NaN                 46.0  \n",
       "2       False     NaN      NaN          NaN   NaN                 27.0  \n",
       "3       False     NaN      NaN          NaN   NaN                 36.0  \n",
       "4       False     NaN      NaN          NaN   NaN                 32.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_full.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# Compute prior gap, and then keep only the data we need to predict\n",
    "find_prior_gap(df_test_full)\n",
    "\n",
    "# Re-divide the two data frames\n",
    "df_test = df_test[~df_test_full['to_predict']]\n",
    "df_test_slots = df_test_full[df_test_full['to_predict']]\n",
    "\n",
    "# Drop extra columns\n",
    "df_test.drop('to_predict', axis = 1, inplace = True)\n",
    "df_test_slots.drop('to_predict', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_district_hash</th>\n",
       "      <th>date</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>gap</th>\n",
       "      <th>gap_before_1</th>\n",
       "      <th>gap_before_2</th>\n",
       "      <th>gap_before_3</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pm25</th>\n",
       "      <th>start_district_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>08232402614a9b48895cc3d0aeb0e9f2</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>08f5b445ec6b29deba62e6fd8b0325a6</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>1afd7afbc81ecc1b13886a569d869e8a</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>1c60154546102e6525f68cb4f31e0657</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>1cbfbdd079ef93e74405c53fcfff8567</td>\n",
       "      <td>2016-01-15</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   start_district_hash        date  timeslot   gap  \\\n",
       "3167  08232402614a9b48895cc3d0aeb0e9f2  2016-01-15      46.0   0.0   \n",
       "3168  08f5b445ec6b29deba62e6fd8b0325a6  2016-01-15      46.0   0.0   \n",
       "3169  1afd7afbc81ecc1b13886a569d869e8a  2016-01-15      46.0  33.0   \n",
       "3170  1c60154546102e6525f68cb4f31e0657  2016-01-15      46.0   1.0   \n",
       "3171  1cbfbdd079ef93e74405c53fcfff8567  2016-01-15      46.0   1.0   \n",
       "\n",
       "      gap_before_1  gap_before_2  gap_before_3  weather  temperature   pm25  \\\n",
       "3167           2.0           1.0           1.0      2.0          4.0  154.0   \n",
       "3168           0.0           0.0           0.0      2.0          4.0  154.0   \n",
       "3169           5.0           4.0           2.0      2.0          4.0  154.0   \n",
       "3170           0.0           1.0           0.0      2.0          4.0  154.0   \n",
       "3171           2.0           0.0           1.0      2.0          4.0  154.0   \n",
       "\n",
       "      start_district_rank  \n",
       "3167                 60.0  \n",
       "3168                 59.0  \n",
       "3169                  9.0  \n",
       "3170                 46.0  \n",
       "3171                 27.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute timeslot\n",
    "compute_timeinfo(df_valid)\n",
    "\n",
    "# Compute gap per time slot per district\n",
    "df_valid = compute_gap(df_valid)\n",
    "\n",
    "# Merge temperature\n",
    "df_valid = merge_weather(df_valid, dfw)\n",
    "\n",
    "# One-hot encoding of districts\n",
    "# df_valid = one_hot_encode(df_valid)\n",
    "\n",
    "# Replace district by popularity\n",
    "df_valid = df_valid.merge(districts_convert, on = 'start_district_hash', how = 'left')\n",
    "\n",
    "# Extract timeslots for testing in validation\n",
    "timeslots = df_test_slots.timeslot.unique()\n",
    "df_valid = df_valid[df_valid['timeslot'].isin(timeslots)]\n",
    "\n",
    "# Check data frame out\n",
    "df_valid.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation for Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Is it a weekend or weekday?\n",
    "compute_timeinfo(df, dateonly = True)\n",
    "compute_timeinfo(df_valid, dateonly = True)\n",
    "compute_timeinfo(df_test, dateonly = True)\n",
    "\n",
    "# Concatenate\n",
    "df_all = pd.concat([df, df_valid, df_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions by Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class predict_by_cluster():\n",
    "    # Make predictions by simply taking the median per start_district_hash per timeslot per weekend\n",
    "    \n",
    "    # Select columns\n",
    "    cols = ['start_district_hash', 'weekend', 'timeslot']\n",
    "    # cols = ['start_district_hash', 'dow', 'timeslot']\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        \n",
    "        # Make prediction data frame\n",
    "        df = df[self.cols + ['gap']]\n",
    "        df_grouped = df.groupby(self.cols)\n",
    "        gap_cluster = df_grouped.median() # median, mean, min, max\n",
    "        gap_cluster = gap_cluster.reset_index().rename(columns = {'gap': 'gap_cluster'})\n",
    "        \n",
    "        self.gap_cluster = gap_cluster\n",
    "\n",
    "    def merge(self, df):\n",
    "        \n",
    "        # Merge gap_cluster in data frame\n",
    "        df = df.merge(self.gap_cluster, on = self.cols, how = 'left')\n",
    "\n",
    "        # Fill missing predictions\n",
    "        df['gap_cluster'] = df['gap_cluster'].fillna(method = 'ffill')\n",
    "        df['gap_cluster'] = df['gap_cluster'].fillna(method = 'bfill')\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Make predictions\n",
    "gap_cluster = predict_by_cluster(df)\n",
    "\n",
    "# Make prediction table per group with ALL the data -- for final submission\n",
    "gap_cluster_all = predict_by_cluster(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge back into main data frame\n",
    "df = gap_cluster.merge(df)\n",
    "\n",
    "# Set given outcome and predictions\n",
    "train_outcome = df['gap']\n",
    "train_predict = df['gap_cluster']\n",
    "\n",
    "# Merge back into main data frame\n",
    "df_valid = gap_cluster.merge(df_valid)\n",
    "\n",
    "# Set given outcome and predictions\n",
    "valid_outcome = df['gap']\n",
    "valid_predict = df['gap_cluster']\n",
    "\n",
    "# Set predictions on test slots\n",
    "df_test_slots = gap_cluster_all.merge(df_test_slots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select features\n",
    "cols = ['start_district_rank', 'dow', 'timeslot', 'temperature', 'gap_before_1', 'gap_before_2', 'gap_before_3']    \n",
    "train = df_all[cols] if final_submission else df[cols]\n",
    "# train.head(5)\n",
    "\n",
    "# Fill missing values\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer()\n",
    "train = imputer.fit_transform(train)\n",
    "\n",
    "# Reference outcome\n",
    "train_outcome = df_all['gap'] if final_submission else df['gap']\n",
    "# train_outcome.head(5)\n",
    "\n",
    "# print(pd.isnull(train).any(1).nonzero()[0])\n",
    "# print(train[pd.isnull(train).any(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit in 2 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Select regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestRegressor(n_estimators = 10)\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# reg = DecisionTreeRegressor(max_depth = 3)\n",
    "\n",
    "# Fit training data\n",
    "start = clock()\n",
    "reg.fit(train, train_outcome)\n",
    "print(\"Fit in {:.0f} seconds.\".format(clock() - start))\n",
    "\n",
    "# Variable importance\n",
    "# print(pd.DataFrame(data = [reg.feature_importances_], columns = train.columns, index = ['importance']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>datetimeslot</th>\n",
       "      <th>district_id</th>\n",
       "      <th>dow</th>\n",
       "      <th>gap</th>\n",
       "      <th>gap_before_1</th>\n",
       "      <th>gap_before_2</th>\n",
       "      <th>gap_before_3</th>\n",
       "      <th>start_district_hash</th>\n",
       "      <th>timeslot</th>\n",
       "      <th>weekend</th>\n",
       "      <th>weather</th>\n",
       "      <th>temperature</th>\n",
       "      <th>pm25</th>\n",
       "      <th>start_district_rank</th>\n",
       "      <th>gap_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-23 00:00:00</td>\n",
       "      <td>2016-01-23-46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>90c5a34f06ac86aee0fd70e2adce7d8a</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-23 00:00:00</td>\n",
       "      <td>2016-01-23-46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f2c8c4bb99e6377d21de71275afd6cd2</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-23 00:00:00</td>\n",
       "      <td>2016-01-23-46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>58c7a4888306d8ff3a641d1c0feccbe3</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-23 00:00:00</td>\n",
       "      <td>2016-01-23-46</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>b26a240205c852804ff8758628c0a86a</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-23 00:00:00</td>\n",
       "      <td>2016-01-23-46</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4b9e4cf2fbdc8281b8a1f9f12b80ce4d</td>\n",
       "      <td>46.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date   datetimeslot  district_id  dow  gap  gap_before_1  \\\n",
       "0  2016-01-23 00:00:00  2016-01-23-46          1.0  5.0  NaN           6.0   \n",
       "1  2016-01-23 00:00:00  2016-01-23-46          2.0  5.0  NaN           1.0   \n",
       "2  2016-01-23 00:00:00  2016-01-23-46          3.0  5.0  NaN           0.0   \n",
       "3  2016-01-23 00:00:00  2016-01-23-46          4.0  5.0  NaN           4.0   \n",
       "4  2016-01-23 00:00:00  2016-01-23-46          5.0  5.0  NaN           2.0   \n",
       "\n",
       "   gap_before_2  gap_before_3               start_district_hash  timeslot  \\\n",
       "0          11.0           9.0  90c5a34f06ac86aee0fd70e2adce7d8a      46.0   \n",
       "1           0.0           0.0  f2c8c4bb99e6377d21de71275afd6cd2      46.0   \n",
       "2           2.0          16.0  58c7a4888306d8ff3a641d1c0feccbe3      46.0   \n",
       "3           8.0          16.0  b26a240205c852804ff8758628c0a86a      46.0   \n",
       "4           1.0           5.0  4b9e4cf2fbdc8281b8a1f9f12b80ce4d      46.0   \n",
       "\n",
       "  weekend  weather  temperature  pm25  start_district_rank  gap_cluster  \n",
       "0    True      NaN          NaN   NaN                  6.0          3.0  \n",
       "1    True      NaN          NaN   NaN                 26.0          0.0  \n",
       "2    True      NaN          NaN   NaN                 51.0          0.0  \n",
       "3    True      NaN          NaN   NaN                 17.0          8.0  \n",
       "4    True      NaN          NaN   NaN                 49.0          0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_slots.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extrapolate\n",
    "train_predict = reg.predict(train)\n",
    "\n",
    "# Validation\n",
    "valid_outcome = df_valid['gap']\n",
    "valid_predict = reg.predict(df_valid[cols])\n",
    "\n",
    "# Set predictions on test slots\n",
    "df_test_slots_imputed = imputer.transform(df_test_slots[cols])\n",
    "# df_test_slots_imputed = df_test_slots[cols]\n",
    "df_test_slots['gap_predict'] = reg.predict(df_test_slots_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "Consider di districts and tj time slots, and the supply-demand gap gapij , and your prediction is sij, we use as the evaluation metrics: \n",
    "![MAPE](figures/mape.jpg)\n",
    "The lowest MAPE will be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAPE: 0.160941\n",
      "Validation MAPE: 0.953641\n"
     ]
    }
   ],
   "source": [
    "def mape(outcome, predict):\n",
    "    \"\"\"\n",
    "    Compute Mean Absolute Percentage Error (MAPE) score. Lower is better.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verify that there are no missing values\n",
    "    try:\n",
    "        assert not (outcome.isnull().values.any() or predict.isnull().values.any())\n",
    "    except AttributeError:\n",
    "        assert not (np.isnan(np.sum(outcome)) or np.isnan(np.sum(outcome)))\n",
    "    \n",
    "    # Get only the NONZERO elements\n",
    "    EPSILON = pow(10, -5)\n",
    "    idx = np.abs(outcome) > EPSILON\n",
    "    \n",
    "    # Extract those elements\n",
    "    outcome = np.array(outcome)[np.where(idx)]\n",
    "    predict = np.array(predict)[np.where(idx)]\n",
    "    \n",
    "    return np.mean(np.abs((outcome - predict) / outcome))\n",
    "\n",
    "score = mape(train_outcome, train_predict)\n",
    "print(\"Training MAPE: {:.6f}\".format(score))\n",
    "\n",
    "score = mape(valid_outcome, valid_predict)\n",
    "print(\"Validation MAPE: {:.6f}\".format(score))\n",
    "\n",
    "# The mean by cluster did #516 with 0.428684 on 2016-06-17."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "<table class=\"table table-2\">\n",
    "        <tr>\n",
    "            <th>Data name</th>\n",
    "            <th>Data type</th>\n",
    "            <th>Example</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>District ID</td>\n",
    "            <td>string</td>\n",
    "            <td>1,2,3,4 (the same as district mapping ID)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Time slot</td>\n",
    "            <td>string</td>\n",
    "            <td>2016-01-23-1 (The first time slot on Jan. 23rd, 2016; one day is uniformly divided into 144 ten minute time slots)</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Prediction value</td>\n",
    "            <td>double</td>\n",
    "            <td>6.0</td>\n",
    "        </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the date - timeslot column\n",
    "df_test_slots['datetimeslot'] = df_test_slots.date.dt.date.map(str) + '-' + df_test_slots.timeslot.astype(int).map(str)\n",
    "\n",
    "# Prepare output file\n",
    "cols = ['district_id', 'datetimeslot', 'gap_predict']\n",
    "df_test_slots[cols].to_csv('predict.csv', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation with other result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Columns in order files\n",
    "cols = ['district_id', 'datetimeslot', 'gap_predict']\n",
    "\n",
    "# Open list of slots\n",
    "order_file = 'predict_final.csv'\n",
    "results_prior = pd.read_csv(order_file, sep = \",\", names = cols)\n",
    "\n",
    "# Compute correlation\n",
    "results = results_prior.merge(df_test_slots[cols], on = ['district_id', 'datetimeslot'])\n",
    "corr = results[['gap_predict_x', 'gap_predict_y']].corr()\n",
    "corr = corr.iloc[0,1]\n",
    "\n",
    "print(\"The correlation between the two results is {:.6f}\".format(corr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
